{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea4b839d-d770-4b40-a44f-c9178e830228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gym\n",
    "from gym import spaces\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from scipy.sparse import coo_matrix\n",
    "import scipy as sp\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c4833d-1f94-475a-9988-48152661c0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6558, 6558)\n",
      "6558\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data preprocessing\n",
    "# Load the Yoochoose dataset and preprocess it to create session-based sequences of interactions\n",
    "data = pd.read_csv('yoochoose_dataset/filtered_clicks.dat',\n",
    "                   names=['session_id', 'timestamp', 'item_id', 'category'],\n",
    "                   dtype={'session_id': 'int64', 'timestamp': 'str', 'item_id': 'int64', 'category': 'int64'},\n",
    "                   parse_dates=['timestamp'])\n",
    "\n",
    "# Create item and session maps\n",
    "item_map = dict(zip(np.unique(data.item_id), range(len(np.unique(data.item_id)))))\n",
    "session_map = dict(zip(np.unique(data.session_id), range(len(np.unique(data.session_id)))))\n",
    "\n",
    "# Map item and session IDs\n",
    "data['item_id'] = data['item_id'].map(item_map)\n",
    "data['session_id'] = data['session_id'].map(session_map)\n",
    "\n",
    "# Sort by session and timestamp\n",
    "data = data.sort_values(['session_id', 'timestamp'])\n",
    "\n",
    "# Create next item and session columns\n",
    "data['next_item_id'] = data.groupby('session_id')['item_id'].shift(-1)\n",
    "data['next_session_id'] = data.groupby('session_id')['session_id'].shift(-1)\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "session_ids = data['session_id'].values.astype('int32')\n",
    "item_ids = data['item_id'].values.astype('int32')\n",
    "next_item_ids = data['next_item_id'].values.astype('int32')\n",
    "next_session_ids = data['next_session_id'].values.astype('int32')\n",
    "timestamps = data['timestamp'].values\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_nodes_from(item_map.values())\n",
    "\n",
    "# Add edges between items that co-occur in the same session\n",
    "for session_id in np.unique(session_ids):\n",
    "    items_in_session = item_ids[session_ids == session_id]\n",
    "    for i in range(len(items_in_session)):\n",
    "        for j in range(i + 1, len(items_in_session)):\n",
    "            if not graph.has_edge(items_in_session[i], items_in_session[j]):\n",
    "                graph.add_edge(items_in_session[i], items_in_session[j], weight=0)\n",
    "            graph[items_in_session[i]][items_in_session[j]]['weight'] += 1\n",
    "\n",
    "# Normalize edge weights\n",
    "for u, v, d in graph.edges(data=True):\n",
    "    d['weight'] /= np.sqrt(graph.degree(u) * graph.degree(v))            \n",
    "\n",
    "# Create adjacency matrix\n",
    "adj_matrix = coo_matrix(nx.to_numpy_array(graph, weight='weight', dtype=np.float32))\n",
    "adj_matrix = tf.sparse.SparseTensor(indices=np.array([adj_matrix.row, adj_matrix.col]).T,\n",
    "                                    values=adj_matrix.data,\n",
    "                                    dense_shape=adj_matrix.shape)    \n",
    "print(adj_matrix.shape)\n",
    "num_nodes = adj_matrix.shape[0] \n",
    "    \n",
    "\n",
    "num_items = num_nodes\n",
    "print(num_items)\n",
    "    \n",
    "embedding_dim = 100\n",
    "num_layers = 2\n",
    "hidden_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570bc935-4673-45ee-b395-da1e698bc4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #split the preprocessed data into train-test sets based on time \n",
    "# #and ensure that there is no item in the test set that does not appear in the training set\n",
    "\n",
    "# latest_timestamp = data['timestamp'].max()\n",
    "# test_fraction = 0.2\n",
    "# test_cutoff_timestamp = latest_timestamp - pd.Timedelta(test_fraction * (latest_timestamp - data['timestamp'].min()))\n",
    "# test_session_ids = data.loc[data['timestamp'] > test_cutoff_timestamp, 'session_id'].unique()\n",
    "# test_data = data.loc[data['session_id'].isin(test_session_ids)]\n",
    "# train_data = data.loc[~data['session_id'].isin(test_session_ids)]\n",
    "# num_sessions = len(train_data['session_id'].unique())\n",
    "# latest_1_4 = train_data.loc[train_data['session_id'].isin(train_data['session_id'].unique()[-num_sessions // 4:])]\n",
    "# latest_1_64 = train_data.loc[train_data['session_id'].isin(train_data['session_id'].unique()[-num_sessions // 64:])]\n",
    "\n",
    "# num_train_sessions_1_4=len(latest_1_4['session_id'].unique())\n",
    "# num_train_sessions_1_64=len(latest_1_64['session_id'].unique())\n",
    "# num_test_sessions=len(test_data['session_id'].unique())\n",
    "\n",
    "# print(f'number of training sessions for 1/64:  {num_train_sessions_1_64}')\n",
    "# # print(f'number of test sessions for 1/64:  {num_test_sessions}')\n",
    "# print(f'number of training sessions for 1/4:  {num_train_sessions_1_4}')\n",
    "# # print(f'number of test sessions for 1/4:  {num_test_sessions}')\n",
    "\n",
    "# num_clicks = len(data)\n",
    "# print(f'number of clicks:  {num_clicks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6d03b5-9111-4aef-87d6-fc24b1d26fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNNActor(tf.keras.Model):\n",
    "    def __init__(self, num_items, num_features, num_edge_features, hidden_dim=100):\n",
    "        super(GNNActor, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.InputLayer(input_shape=(None, num_features + num_edge_features), sparse=True)\n",
    "        self.num_items = num_items\n",
    "        self.num_features = num_features\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Define node embedding layer\n",
    "        self.node_embedding = tf.keras.layers.Embedding(input_dim=num_items, output_dim=hidden_dim, input_length=1)\n",
    "\n",
    "        # Define graph convolutional layers\n",
    "        self.gcn_layer1 = tf.keras.layers.Dense(units=hidden_dim, activation='relu')\n",
    "        self.gcn_layer2 = tf.keras.layers.Dense(units=hidden_dim, activation='relu')\n",
    "        \n",
    "        # Define final prediction layer\n",
    "        self.prediction_layer = tf.keras.layers.Dense(units=num_items, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Check input shape and extract node and edge features accordingly\n",
    "        # print(f'inputs.shape {inputs.shape}')\n",
    "        if len(inputs.shape) == 1:\n",
    "            # print(f'GNN inputs shape: {inputs.shape}')\n",
    "            node_features = tf.expand_dims(tf.range(self.num_items), axis=-1)\n",
    "            edge_features = inputs\n",
    "            # Reshape edge_features tensor\n",
    "            edge_features = tf.expand_dims(edge_features, axis=-1) # (batch_size, num_edge_features, num_edges, 1)\n",
    "        else:\n",
    "            node_features = inputs[:, :1]\n",
    "            edge_features = inputs[:, 1:]\n",
    "        # Node embedding layer\n",
    "        # print(f'node_features shape: {node_features.shape}')\n",
    "        node_embeddings = self.node_embedding(node_features) # (batch_size, 1, hidden_dim)\n",
    "        # print(f'node_embeddings shape: {node_embeddings.shape}')\n",
    "        # print(f'node_embeddings: {node_embeddings}')\n",
    "        # print(f'edge_features shape: {edge_features.shape}')\n",
    "        # print(f'edge_features: {edge_features}')\n",
    "        \n",
    "        # Matmul edge_features and node_embeddings tensors\n",
    "        hidden1 = self.gcn_layer1(tf.linalg.matmul(tf.expand_dims(edge_features, axis=-1), node_embeddings)) # (batch_size, num_edge_features, num_edges, hidden_dim)\n",
    "        hidden1 = tf.reshape(hidden1, [-1, self.num_edge_features, self.hidden_dim]) # (batch_size, num_edge_features, hidden_dim)\n",
    "        hidden2 = self.gcn_layer2(tf.linalg.matmul(edge_features, hidden1)) # (batch_size, num_edge_features, num_edges, hidden_dim)\n",
    "        hidden2 = tf.reshape(hidden2, [-1, self.num_edge_features, self.hidden_dim]) # (batch_size, num_edge_features, hidden_dim)\n",
    "    \n",
    "        # Concatenate node features and hidden layers\n",
    "        concat_features = tf.concat([node_embeddings, hidden1, hidden2], axis=-1) # (batch_size, 1, 3*hidden_dim)\n",
    "\n",
    "        # Final prediction layer\n",
    "        predictions = self.prediction_layer(tf.squeeze(concat_features, axis=1)) # (batch_size, num_items)\n",
    "        print(f'Predictions shape: {predictions.shape}')\n",
    "        print(f'Predictions: {predictions}')\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class DQNCritic(tf.keras.Model):\n",
    "    def __init__(self, num_items, hidden_dim=100):\n",
    "        super(DQNCritic, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Define dense layers\n",
    "        self.dense1 = tf.keras.layers.Dense(units=hidden_dim, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=1, activation=None)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Pass input through dense layers\n",
    "        print(f'DQN inputs.shape {inputs.shape}')\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        # Reshape output to (batch_size, num_items)\n",
    "        q_values = tf.reshape(x, shape=(-1, self.num_items))\n",
    "        print(f'q_values {q_values.shape}')\n",
    "        return q_values\n",
    "    \n",
    "class RecommenderEnv(gym.Env):\n",
    "    def __init__(self, session_ids, item_ids, next_item_ids, next_session_ids, adj_matrix):\n",
    "        super(RecommenderEnv, self).__init__()\n",
    "\n",
    "        self.session_ids = session_ids\n",
    "        self.item_ids = item_ids\n",
    "        self.next_item_ids = next_item_ids\n",
    "        self.next_session_ids = next_session_ids\n",
    "        self.adj_matrix = adj_matrix\n",
    "\n",
    "        self.num_items = adj_matrix.shape[0]\n",
    "        self.num_sessions = len(np.unique(session_ids))\n",
    "\n",
    "        self.action_space = spaces.Discrete(self.num_items)\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.num_items,))\n",
    "\n",
    "        self.current_session = 0\n",
    "        self.current_session_items = set(self.item_ids[self.session_ids == self.current_session])\n",
    "        self.current_state = np.zeros(self.num_items)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_session = 0\n",
    "        self.current_session_items = set(self.item_ids[self.session_ids == self.current_session])\n",
    "        self.current_state = np.zeros(self.num_items)\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Update current state\n",
    "        self.current_state[action] = 1\n",
    "\n",
    "        # Get the reward for the action\n",
    "        if action.ref() in self.current_session_items:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        # Move to the next session if the current session has ended\n",
    "        if self.next_session_ids[self.current_session] != self.current_session:\n",
    "            self.current_session = self.next_session_ids[self.current_session]\n",
    "            self.current_session_items = set(self.item_ids[self.session_ids == self.current_session])\n",
    "\n",
    "        # Check if the episode is over\n",
    "        done = self.current_session == self.num_sessions - 1\n",
    "\n",
    "        return self.current_state, reward, done, {}\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9571b3f-c752-4f89-ab54-375bd9a2b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN model compiled\n",
      "DQN model compiled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state shape: (6558,)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Define instance of environment \n",
    "env = RecommenderEnv(session_ids, item_ids, next_item_ids, next_session_ids, adj_matrix)\n",
    "    \n",
    "# Define the GNNActor model\n",
    "gnn_actor = GNNActor(num_items, num_features=1, num_edge_features=1, hidden_dim=100)\n",
    "\n",
    "\n",
    "# Define the DQNCritic model\n",
    "dqn_critic = DQNCritic(num_items, hidden_dim=100)\n",
    "\n",
    "\n",
    "# Define the loss function for the DQN\n",
    "def dqn_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "discount_factor = 0.99\n",
    "exploration_rate = 1.0\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.001\n",
    "num_episodes = 1000\n",
    "replay_buffer_size = 100000\n",
    "\n",
    "# Define the optimizer for both models\n",
    "optimizer = Adam(learning_rate)\n",
    "\n",
    "# Compile both models\n",
    "gnn_actor.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "print(\"GNN model compiled\")\n",
    "dqn_critic.compile(optimizer=optimizer, loss=dqn_loss)\n",
    "print(\"DQN model compiled\")\n",
    "\n",
    "# Create replay buffer\n",
    "replay_buffer = deque(maxlen=replay_buffer_size)\n",
    "\n",
    "# Define optimizers\n",
    "actor_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "critic_optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Define the function to sample a batch of experiences\n",
    "def sample_batch(replay_buffer, batch_size):\n",
    "    batch = random.sample(replay_buffer, batch_size)\n",
    "    states = np.array([experience[0] for experience in batch])\n",
    "    actions = np.array([experience[1] for experience in batch])\n",
    "    rewards = np.array([experience[2] for experience in batch])\n",
    "    next_states = np.array([experience[3] for experience in batch])\n",
    "    dones = np.array([experience[4] for experience in batch])\n",
    "    return states, actions, rewards, next_states, dones\n",
    "\n",
    "# Define the function to compute the target Q-values\n",
    "@tf.function\n",
    "def compute_target_q_values(next_states, next_gnn_embeddings):\n",
    "    next_states = tf.reshape(next_states, (next_states.shape[0], 1, -1))\n",
    "    next_actions = actor_model([next_gnn_embeddings, next_states])\n",
    "    next_q_values = critic_model([next_states, next_actions])\n",
    "    return rewards + discount_factor * (1 - dones) * tf.squeeze(next_q_values)\n",
    "num_features = 1\n",
    "@tf.function\n",
    "def compute_gradients(batch):\n",
    "    states, actions, rewards, next_states, dones = batch\n",
    "\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Compute logits for GNNActor\n",
    "        # print(f'states.shape {states.shape}')\n",
    "        action_probs = gnn_actor(states)\n",
    "        selected_action_probs = tf.gather(action_probs, actions, batch_dims=1)\n",
    "        log_probs = tf.math.log(selected_action_probs)\n",
    "\n",
    "        # Compute Q values for DQNCritic\n",
    "        state_features = tf.convert_to_tensor(states, dtype=tf.float32)\n",
    "        next_state_features = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
    "        q_values = dqn_critic(state_features)\n",
    "        next_q_values = target_dqn_critic(next_state_features)\n",
    "        target_q_values = rewards + gamma * tf.reduce_max(next_q_values, axis=1)\n",
    "        td_errors = target_q_values - tf.gather(q_values, actions, batch_dims=1)\n",
    "\n",
    "    # Compute gradients for GNNActor\n",
    "    actor_gradients = tape.gradient(-log_probs, gnn_actor.trainable_variables)\n",
    "\n",
    "    # Compute gradients for DQNCritic\n",
    "    critic_gradients = tape.gradient(td_errors, dqn_critic.trainable_variables)\n",
    "\n",
    "    return actor_gradients, critic_gradients\n",
    "\n",
    "def apply_gradients(actor_gradients, critic_gradients):\n",
    "    # Apply gradients to the GNNActor\n",
    "    gnn_actor_optimizer.apply_gradients(zip(actor_gradients, gnn_actor.trainable_variables))\n",
    "\n",
    "    # Apply gradients to the DQNCritic\n",
    "    q_critic_optimizer.apply_gradients(zip(critic_gradients, q_critic.trainable_variables))\n",
    "\n",
    "\n",
    "def update_target_networks(gnn_actor, dqn_critic, target_gnn_actor, target_dqn_critic, tau):\n",
    "    for target_param, param in zip(target_gnn_actor.parameters(), gnn_actor.parameters()):\n",
    "        target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "\n",
    "    for target_param, param in zip(target_dqn_critic.parameters(), dqn_critic.parameters()):\n",
    "        target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "\n",
    "    \n",
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "gamma = 0.99  # discount factor\n",
    "tau = 0.001  # target network update rate\n",
    "actor_lr = 0.001\n",
    "critic_lr = 0.001\n",
    "max_episodes = 1000  # maximum number of episodes to run\n",
    "max_steps_per_episode = 100  # maximum number of steps per episode\n",
    "replay_buffer_size = int(1e6)\n",
    "\n",
    "\n",
    "# Initialize target networks\n",
    "target_gnn_actor = GNNActor(num_items, num_features=1, num_edge_features=1, hidden_dim=100)\n",
    "target_gnn_actor.set_weights(gnn_actor.get_weights())\n",
    "target_dqn_critic = DQNCritic(num_items, hidden_dim)\n",
    "target_dqn_critic.set_weights(dqn_critic.get_weights())\n",
    "\n",
    "# Train the GNNActor and DQNCritic models jointly for session-based recommendation\n",
    "\n",
    "# Define training loop\n",
    "for episode in tqdm(range(max_episodes)):\n",
    "    # Reset environment and get initial state\n",
    "    state = env.reset()\n",
    "    print(f'state shape: {state.shape}')\n",
    "    episode_reward = 0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        \n",
    "        # Sample action from GNNActor\n",
    "        action_probs = gnn_actor(state)\n",
    "        # print(f'action_probs: {action_probs}')\n",
    "        # Sample an action from the predicted probability distribution\n",
    "        action = tf.random.categorical(action_probs, num_samples=1)[0, 0]\n",
    "        # print(f'action: {action}')\n",
    "        # Take action in environment\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Update episode reward\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # Add experience to replay buffer\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        # Sample batch from replay buffer\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            # Sample batch of experiences from replay buffer\n",
    "            batch = sample_batch(replay_buffer, batch_size)\n",
    "\n",
    "            # Compute gradients for GNNActor and DQNCritic\n",
    "            actor_gradients, critic_gradients = compute_gradients(batch)\n",
    "            \n",
    "            # Apply gradients to GNNActor and DQNCritic\n",
    "            apply_gradients(actor_gradients, critic_gradients, actor_optimizer, critic_optimizer)\n",
    "            \n",
    "            # Update target networks\n",
    "            update_target_networks(gnn_actor, dqn_critic, target_gnn_actor, target_dqn_critic, tau)\n",
    "        \n",
    "        # Update state\n",
    "        state = next_state\n",
    "        \n",
    "        # Check if episode is done\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    # Print episode reward\n",
    "    print(f'Episode {episode}: {episode_reward}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a44f71-8114-43ed-b8ab-1ea422ab9a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed31ca57-33da-46e3-b82e-61bf4287f6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
